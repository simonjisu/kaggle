{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 0 if USE_CUDA else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02a591ba9b196c3fb5e1327963b9a5d1a9b616bc"
   },
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "* 0 : negative\n",
    "* 1 : somewhat negative\n",
    "* 2 : neutral\n",
    "* 3 : somewhat positive\n",
    "* 4 : positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "32a050b651a3ac10aff49c3f0dd536fe28da79ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sentence_idx: 7676\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/SentimentAnalysis/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../data/SentimentAnalysis/test.tsv', sep='\\t')\n",
    "train_idx = int(len(train.drop_duplicates('SentenceId')) * 0.9)\n",
    "print('train_sentence_idx: {}'.format(train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "40264d9158989eb1961f2ab719c83a18beafa50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 141485, valid_data: 14575\n"
     ]
    }
   ],
   "source": [
    "split_idx = train.loc[train.SentenceId == train_idx].index[-1] + 1\n",
    "valid = train.iloc[split_idx:, :]\n",
    "train = train.iloc[:split_idx, :]\n",
    "print('train_data: {}, valid_data: {}'.format(len(train), len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e3d11af04ac78341f64c3da052b345206b3fd14"
   },
   "outputs": [],
   "source": [
    "def write_files(path, data, test=False):\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        if test:\n",
    "            for phrase in data:\n",
    "                print(phrase, file=file)\n",
    "        else:\n",
    "            for phrase, sent in data:\n",
    "                print('\\t'.join([phrase, str(sent)]), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a9fb1173a481a0b91d7082445056a385ac779a6"
   },
   "outputs": [],
   "source": [
    "write_files('./train_data.txt', train.iloc[:, 2:].values)\n",
    "write_files('./valid_data.txt', valid.iloc[:, 2:].values)\n",
    "write_files('./test_data.txt', test.iloc[:, -1].values, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "77121d57146cc7789fe0454cfbbef18020f0ccc0"
   },
   "outputs": [],
   "source": [
    "PHRASE = Field(tokenize=str.split, use_vocab=True, lower=True, include_lengths=True,\n",
    "               batch_first=True)\n",
    "SENT = Field(sequential=False, use_vocab=False, preprocessing=lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "63e140a75bb98f97029892a77fde595061420c6c"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = TabularDataset.splits(\n",
    "       path='./', train='train_data.txt', validation=\"valid_data.txt\", \n",
    "       format='tsv', fields=[('phrase', PHRASE), ('sent', SENT)])\n",
    "test_data = TabularDataset.splits(\n",
    "       path='./', test='test_data.txt', format='tsv', fields=[('phrase', PHRASE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c14c3368c4511f6e77d69f0316c80766998c3f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocabulary: 15648\n"
     ]
    }
   ],
   "source": [
    "PHRASE.build_vocab(train_data)\n",
    "print('number of vocabulary: {}'.format(len(PHRASE.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b5ef97ce0e437cb5df9d43552830cee37f9a6c61"
   },
   "outputs": [],
   "source": [
    "BATCH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "164977d111ec5f35ba01a9b07692841c2bd2afde"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data[0]), batch_size=BATCH, device=DEVICE,\n",
    "    sort_key=lambda x: len(x.phrase), sort_within_batch=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "f30e2b4513caf079bb65be2bc52bbc6949120bd5"
   },
   "outputs": [],
   "source": [
    "class bidirec_GRU(nn.Module):\n",
    "    def __init__(self, V, D, H, H_f, O, da, r, num_layers=3, bidirec=False, use_cuda=False):\n",
    "        \"\"\"\n",
    "        V: input_size = vocab_size\n",
    "        D: embedding_size\n",
    "        H: hidden_size\n",
    "        H_f: hidden_size (fully-connected)\n",
    "        O: output_size (fully-connected)\n",
    "        da: attenion_dimension (hyperparameter)\n",
    "        r: keywords (different parts to be extracted from the sentence)\n",
    "        \"\"\"\n",
    "        super(bidirec_GRU, self).__init__()\n",
    "        self.r = r\n",
    "        self.da = da\n",
    "        self.hidden_size = H\n",
    "        self.num_layers = num_layers\n",
    "        self.USE_CUDA = use_cuda\n",
    "        self.num_directions = 2 if bidirec else 1\n",
    "        \n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.gru = nn.GRU(D, H, num_layers, batch_first=True, bidirectional=bidirec)\n",
    "        self.attn = nn.Linear(self.num_directions*H, self.da, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.attn2 = nn.Linear(self.da, self.r, bias=False)\n",
    "        self.attn_dist = nn.Softmax(dim=2)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(r*H*self.num_directions, H_f),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H_f, O)\n",
    "        )\n",
    "            \n",
    "    def init_GRU(self, batch_size):\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        hidden = torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size)\n",
    "        if self.USE_CUDA:\n",
    "            hidden = hidden.cuda()\n",
    "        return hidden\n",
    "    \n",
    "    def penalization_term(self, A):\n",
    "        \"\"\"\n",
    "        A : B, r, T\n",
    "        Frobenius Norm \n",
    "        \"\"\"\n",
    "        eye = torch.eye(A.size(1)).expand(A.size(0), self.r, self.r) # B, r, r\n",
    "        if self.USE_CUDA:\n",
    "            eye = eye.cuda()\n",
    "        P = torch.bmm(A, A.transpose(1, 2)) - eye # B, r, r\n",
    "        loss_P = ((P**2).sum(1).sum(1) + 1e-10) ** 0.5\n",
    "        loss_P = torch.sum(loss_P) / A.size(0)\n",
    "        return loss_P\n",
    "        \n",
    "    def forward(self, inputs, inputs_lengths):\n",
    "        \"\"\"\n",
    "        inputs: B, T, V\n",
    "         - B: batch_size\n",
    "         - T: max_len = seq_len\n",
    "         - V: vocab_size\n",
    "        inputs_lengths: length of each sentences\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs)  # B, T, V  --> B, T, D\n",
    "        hidden = self.init_GRU(inputs.size(0))  # num_layers * num_directions, B, H\n",
    "        # pack sentences\n",
    "        packed = pack_padded_sequence(embed, inputs_lengths.tolist(), batch_first=True)\n",
    "        # packed: B * real_length, D\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        # output: B * T, 2H\n",
    "        # hidden: num_layers * num_directions, B, H\n",
    "        \n",
    "        # unpack sentences\n",
    "        output, output_lengths = pad_packed_sequence(output, batch_first=True) \n",
    "        # output: B, T, 2H\n",
    "\n",
    "        # Self Attention\n",
    "        a1 = self.attn(output)  # Ws1(B, da, 2H) * output(B, T, 2H) -> B, T, da\n",
    "        tanh_a1 = self.tanh(a1)  # B, T, da\n",
    "        score = self.attn2(tanh_a1)  # Ws2(B, r, da) * tanh_a1(B, T, da) -> B, T, r\n",
    "        self.A = self.attn_dist(score.transpose(1, 2))  # B, r, T\n",
    "        self.M = self.A.bmm(output)  # B, r, T * B, T, 2H -> B, r, 2H \n",
    "        \n",
    "        # Penalization Term\n",
    "        loss_P = self.penalization_term(self.A)\n",
    "        \n",
    "        output = self.fc(self.M.view(self.M.size(0), -1)) # B, r, 2H -> resize to B, r*2H -> B, H_f -> Relu -> B, 1\n",
    "        \n",
    "        return output, loss_P\n",
    "    \n",
    "    def predict(self, inputs, inputs_lengths):\n",
    "        preds, _ = self.forward(inputs, inputs_lengths)\n",
    "        _, idx = F.softmax(preds, dim=1).max(1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "c4a12dd6ddfb267cda4fef91171e34fedce03bb3"
   },
   "outputs": [],
   "source": [
    "V = len(PHRASE.vocab)\n",
    "D = 100\n",
    "H = 300\n",
    "H_f = 1000\n",
    "O = 5\n",
    "DA = 300\n",
    "R = 10\n",
    "N_LAYERS = 1\n",
    "bidirec = True\n",
    "weight_decay_rate = 0.0001\n",
    "LR = 0.01\n",
    "STEP = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "26b803859f43c1dcda5e1727efac8c991d80071b"
   },
   "outputs": [],
   "source": [
    "model = bidirec_GRU(V, D, H, H_f, O, DA, R, \n",
    "                    num_layers=N_LAYERS, bidirec=bidirec, use_cuda=USE_CUDA)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "17c8f44bddd549a94b3e28fc03b4e0f58c518cc3"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.1, milestones=[5, 15, 20], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "3526a7043f98672b4854c1a38644e23315016901"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/usr/local/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] train_loss: 4.5219, valid_loss: 4.0295, lr: 0.0100\n",
      "[2/30] train_loss: 5.9502, valid_loss: 4.7035, lr: 0.0100\n",
      "[3/30] train_loss: 5.4246, valid_loss: 4.7960, lr: 0.0100\n",
      "[4/30] train_loss: 8.5222, valid_loss: 7.9284, lr: 0.0100\n",
      "[5/30] train_loss: 10.8120, valid_loss: 7.4146, lr: 0.0100\n",
      "[6/30] train_loss: 9.5773, valid_loss: 6.1754, lr: 0.0100\n",
      "[7/30] train_loss: 10.5724, valid_loss: 6.8577, lr: 0.0100\n",
      "[8/30] train_loss: 10.3974, valid_loss: 6.8107, lr: 0.0100\n",
      "[9/30] train_loss: 10.2966, valid_loss: 6.4475, lr: 0.0100\n",
      "[10/30] train_loss: 9.9651, valid_loss: 6.8658, lr: 0.0100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5460236ebae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_P\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-49ce53be0bea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, inputs_lengths)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ws1(B, da, 2H) * output(B, T, 2H) -> B, T, da\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mtanh_a1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B, T, da\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtanh_a1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ws2(B, r, da) * tanh_a1(B, T, da) -> B, T, r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_losses = [10e5]\n",
    "model.train()\n",
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    # train\n",
    "    for batch in train_loader:\n",
    "        inputs, lengths = batch.phrase\n",
    "        targets = batch.sent\n",
    "        if 0 in lengths:\n",
    "            inputs = inputs[lengths.ne(0)]\n",
    "            targets = targets[lengths.ne(0)]\n",
    "            lengths = lengths[lengths.ne(0)]\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        preds, loss_P = model(inputs, lengths)\n",
    "        \n",
    "        loss = loss_function(preds, targets) + loss_P\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # valid\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    for batch in valid_loader:\n",
    "        inputs, lengths = batch.phrase\n",
    "        targets = batch.sent\n",
    "        if 0 in lengths:\n",
    "            inputs = inputs[lengths.ne(0)]\n",
    "            targets = targets[lengths.ne(0)]\n",
    "            lengths = lengths[lengths.ne(0)]\n",
    "        \n",
    "        preds, loss_P = model(inputs, lengths)\n",
    "        v_loss = loss_function(preds, targets) + loss_P\n",
    "        valid_loss.append(v_loss.item())\n",
    "        \n",
    "    valid_losses.append(np.mean(valid_loss))\n",
    "    \n",
    "    if valid_losses[-2] - valid_losses[-1] < 0:\n",
    "        torch.save(model.state_dict(), './model/model({}_{:.4f})'.format(step, np.mean(valid_loss)))\n",
    "        \n",
    "    string = '[{}/{}] train_loss: {:.4f}, valid_loss: {:.4f}, lr: {:.4f}'.format(\n",
    "        step+1, STEP, np.mean(losses), np.mean(valid_loss), scheduler.get_lr()[0])\n",
    "    print(string)\n",
    "    losses = []\n",
    "    valid_loss = []\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model/model({}_{:.4f})'.format(step, np.mean(valid_loss)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
